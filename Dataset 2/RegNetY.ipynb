{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T07:31:51.060256Z",
     "iopub.status.busy": "2024-10-26T07:31:51.059897Z",
     "iopub.status.idle": "2024-10-26T07:31:56.859924Z",
     "shell.execute_reply": "2024-10-26T07:31:56.859093Z",
     "shell.execute_reply.started": "2024-10-26T07:31:51.060223Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from timm import create_model\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T07:31:56.862218Z",
     "iopub.status.busy": "2024-10-26T07:31:56.861620Z",
     "iopub.status.idle": "2024-10-26T07:31:56.994355Z",
     "shell.execute_reply": "2024-10-26T07:31:56.993589Z",
     "shell.execute_reply.started": "2024-10-26T07:31:56.862190Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "bee = np.load('bee.npy')\n",
    "nobee = np.load('nobee.npy')\n",
    "noqueen = np.load('noqueen.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T07:31:56.995957Z",
     "iopub.status.busy": "2024-10-26T07:31:56.995611Z",
     "iopub.status.idle": "2024-10-26T07:31:57.001974Z",
     "shell.execute_reply": "2024-10-26T07:31:57.001065Z",
     "shell.execute_reply.started": "2024-10-26T07:31:56.995926Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "labels_bee = np.ones(len(bee)) * 1  \n",
    "labels_nobee = np.ones(len(nobee)) * 0  \n",
    "labels_noqueen = np.ones(len(noqueen)) * 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T07:31:57.003953Z",
     "iopub.status.busy": "2024-10-26T07:31:57.003680Z",
     "iopub.status.idle": "2024-10-26T07:31:57.163828Z",
     "shell.execute_reply": "2024-10-26T07:31:57.162838Z",
     "shell.execute_reply.started": "2024-10-26T07:31:57.003929Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = np.concatenate((bee, nobee, noqueen), axis=0)\n",
    "labels = np.concatenate((labels_bee, labels_nobee, labels_noqueen), axis=0)\n",
    "\n",
    "df = pd.DataFrame({'data': list(data), 'labels': labels})\n",
    "df = df.sample(frac=1).reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T07:31:57.286616Z",
     "iopub.status.busy": "2024-10-26T07:31:57.286225Z",
     "iopub.status.idle": "2024-10-26T07:31:57.442610Z",
     "shell.execute_reply": "2024-10-26T07:31:57.441590Z",
     "shell.execute_reply.started": "2024-10-26T07:31:57.286575Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['labels'])\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.15, random_state=42, stratify=train_df['labels'])\n",
    "\n",
    "x_train = np.array(train_df['data'].tolist())\n",
    "y_train = np.array(train_df['labels'].tolist())\n",
    "\n",
    "x_val = np.array(val_df['data'].tolist())\n",
    "y_val = np.array(val_df['labels'].tolist())\n",
    "\n",
    "x_test = np.array(test_df['data'].tolist())\n",
    "y_test = np.array(test_df['labels'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T07:31:57.780738Z",
     "iopub.status.busy": "2024-10-26T07:31:57.779860Z",
     "iopub.status.idle": "2024-10-26T07:31:57.784970Z",
     "shell.execute_reply": "2024-10-26T07:31:57.784000Z",
     "shell.execute_reply.started": "2024-10-26T07:31:57.780705Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train[..., np.newaxis]\n",
    "x_val = x_val[..., np.newaxis]\n",
    "x_test = x_test[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T07:32:00.546829Z",
     "iopub.status.busy": "2024-10-26T07:32:00.545976Z",
     "iopub.status.idle": "2024-10-26T07:32:00.553039Z",
     "shell.execute_reply": "2024-10-26T07:32:00.552026Z",
     "shell.execute_reply.started": "2024-10-26T07:32:00.546798Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BeeDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T07:32:01.640599Z",
     "iopub.status.busy": "2024-10-26T07:32:01.639911Z",
     "iopub.status.idle": "2024-10-26T07:32:01.645207Z",
     "shell.execute_reply": "2024-10-26T07:32:01.644325Z",
     "shell.execute_reply.started": "2024-10-26T07:32:01.640562Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),  \n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T07:32:02.694210Z",
     "iopub.status.busy": "2024-10-26T07:32:02.693880Z",
     "iopub.status.idle": "2024-10-26T07:32:02.699136Z",
     "shell.execute_reply": "2024-10-26T07:32:02.698092Z",
     "shell.execute_reply.started": "2024-10-26T07:32:02.694185Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = BeeDataset(x_train, y_train, transform=transform)\n",
    "val_dataset = BeeDataset(x_val, y_val, transform=transform)\n",
    "test_dataset = BeeDataset(x_test, y_test, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T07:32:03.801372Z",
     "iopub.status.busy": "2024-10-26T07:32:03.800681Z",
     "iopub.status.idle": "2024-10-26T07:32:03.806608Z",
     "shell.execute_reply": "2024-10-26T07:32:03.805608Z",
     "shell.execute_reply.started": "2024-10-26T07:32:03.801338Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T07:32:04.868983Z",
     "iopub.status.busy": "2024-10-26T07:32:04.868656Z",
     "iopub.status.idle": "2024-10-26T07:32:04.908788Z",
     "shell.execute_reply": "2024-10-26T07:32:04.907827Z",
     "shell.execute_reply.started": "2024-10-26T07:32:04.868958Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T07:32:05.771537Z",
     "iopub.status.busy": "2024-10-26T07:32:05.770771Z",
     "iopub.status.idle": "2024-10-26T07:32:05.779368Z",
     "shell.execute_reply": "2024-10-26T07:32:05.778583Z",
     "shell.execute_reply.started": "2024-10-26T07:32:05.771492Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "# Ensure deterministic behavior\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T07:32:39.983909Z",
     "iopub.status.busy": "2024-10-26T07:32:39.983253Z",
     "iopub.status.idle": "2024-10-26T07:32:40.789789Z",
     "shell.execute_reply": "2024-10-26T07:32:40.788778Z",
     "shell.execute_reply.started": "2024-10-26T07:32:39.983867Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the CaiT model with pretrained weights\n",
    "model = create_model('cait_xxs36_224', pretrained=True)\n",
    "\n",
    "use_bias = model.patch_embed.proj.bias is not None\n",
    "\n",
    "model.patch_embed.proj = nn.Conv2d(\n",
    "    in_channels=1,  \n",
    "    out_channels=model.patch_embed.proj.out_channels,\n",
    "    kernel_size=model.patch_embed.proj.kernel_size,\n",
    "    stride=model.patch_embed.proj.stride,\n",
    "    padding=model.patch_embed.proj.padding,\n",
    "    bias=use_bias  \n",
    ")\n",
    "\n",
    "model.head = nn.Linear(model.head.in_features, 3)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T07:32:45.165925Z",
     "iopub.status.busy": "2024-10-26T07:32:45.165044Z",
     "iopub.status.idle": "2024-10-26T11:53:40.447806Z",
     "shell.execute_reply": "2024-10-26T11:53:40.446914Z",
     "shell.execute_reply.started": "2024-10-26T07:32:45.165891Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Training and validation loop\n",
    "num_epochs = 30\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val_accuracy = 0\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_corrects = 0\n",
    "\n",
    "    for train_images, train_labels in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}\"):\n",
    "        train_images = train_images.to(device)\n",
    "        train_labels = train_labels.long().to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(train_images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, train_labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * train_images.size(0)\n",
    "        train_corrects += torch.sum(preds == train_labels.data)\n",
    "\n",
    "    train_loss /= len(train_dataloader.dataset)\n",
    "    train_acc = train_corrects.double() / len(train_dataloader.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_corrects = 0\n",
    "    with torch.no_grad():\n",
    "        for val_images, val_labels in tqdm(val_dataloader, desc=f\"Epoch {epoch+1} Validation\"):\n",
    "            val_images = val_images.to(device)\n",
    "            val_labels = val_labels.long().to(device)\n",
    "            \n",
    "            val_outputs = model(val_images)\n",
    "            _, preds = torch.max(val_outputs, 1)\n",
    "            loss = criterion(val_outputs, val_labels)\n",
    "            \n",
    "            val_loss += loss.item() * val_images.size(0)\n",
    "            val_corrects += torch.sum(preds == val_labels.data)\n",
    "\n",
    "    val_loss /= len(val_dataloader.dataset)\n",
    "    val_acc = val_corrects.double() / len(val_dataloader.dataset)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "   \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T11:55:22.922929Z",
     "iopub.status.busy": "2024-10-26T11:55:22.922225Z",
     "iopub.status.idle": "2024-10-26T11:55:38.320032Z",
     "shell.execute_reply": "2024-10-26T11:55:38.319038Z",
     "shell.execute_reply.started": "2024-10-26T11:55:22.922896Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "best_model = model\n",
    "best_model.load_state_dict(torch.load('/kaggle/working/best_model.pth'))\n",
    "\n",
    "# Predict on the test set\n",
    "best_model.eval()\n",
    "test_predictions = []\n",
    "true_labels = []\n",
    "with torch.no_grad():\n",
    "    for test_images, test_labels in tqdm(test_dataloader, desc=\"Test Set\"):\n",
    "        test_images = test_images.to(device)\n",
    "        test_labels = test_labels.long().to(device)\n",
    "        \n",
    "        outputs = best_model(test_images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        test_predictions.extend(preds.cpu().numpy())\n",
    "        true_labels.extend(test_labels.cpu().numpy())\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "num_correct = sum([1 for i in range(len(test_predictions)) if test_predictions[i] == true_labels[i]])\n",
    "test_accuracy = num_correct / len(test_predictions)\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(true_labels, test_predictions)\n",
    "print(f'Confusion Matrix:\\n{cm}')\n",
    "\n",
    "# Calculate F1 score (macro, weighted, or per-class)\n",
    "f1 = f1_score(true_labels, test_predictions, average='macro')  \n",
    "print(f'F1 Score (Macro): {f1:.2f}')\n",
    "\n",
    "# Plot confusion matrix using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[str(i) for i in range(len(cm))], yticklabels=[str(i) for i in range(len(cm))])\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
