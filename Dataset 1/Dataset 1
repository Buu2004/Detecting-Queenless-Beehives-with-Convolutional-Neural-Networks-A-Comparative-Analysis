}This assessment employs a real dataset of audio recordings collected in 2022 from various beehives at the Research Center
for Tropical Bees and Beekeeping, Vietnam National University of Agriculture, as introduced in a previous study. The recordings,
captured under different ambient noise conditions, are divided into two categories: those with and without the presence of the 
queen bee. The audio data is then segmented into 20,000 clips, each 2-second-long with 1-second overlaps, ensuring consistent analysis. 
This method is similar to a previous approach where each 30-second audio clip was divided into 2-second segments with a 1-second overlap,
resulting in 28 segments per 30-second audio file. To evaluate deep learning methods, we split the dataset into a training set (70\%), 
validation set (10\%) and a testing set (20\%) for model training and evaluation, respectively.
